# Neural Style Transfer

Neural Style Transfer (NST) is a technique that allows combining the content of one image with the style of another image to create a composite image that maintains the content of the original but adopts the stylistic elements of the second image. This project showcases the use of NST for artistic applications, photo editing, and more.

Overview
Neural Style Transfer (NST) leverages Convolutional Neural Networks (CNNs), particularly using pre-trained models like VGG-19, to perform style transfer by optimizing the pixel values of the input image.

Table of Contents
Content and Style Images
Feature Extraction
Gram Matrix
Loss Function
Generating the Stylized Image
Installation
Libraries Used
Usage
Examples
Author
Content and Style Images
Content Image:

Style Image:

Result:

Feature Extraction
Feature extraction is performed using a pre-trained VGG-19 model to get the content and style representations of the images. These features are then used to compute the content and style losses.

Gram Matrix
The Gram matrix is used to capture the style of the image by representing the correlations between different filter responses of the CNN.

Loss Function
Content Loss:
Measures how much the content of the generated image deviates from the content image.

Style Loss:
Measures how much the style of the generated image deviates from the style image.

Generating the Stylized Image
The stylized image is generated by optimizing the pixel values of the content image to minimize the combined content and style loss.

Installation
To run this project, follow these steps:

Clone the repository:
bash
Copy code
git clone https://github.com/archieagarwal/neural-style-transfer.git
Upload the code file and images to Google Colab.
Run the cells in the provided Jupyter notebook.
Libraries Used
Numpy:
Used for a variety of mathematical operations on arrays. It is efficient and fast.

TensorFlow:
A comprehensive library for machine learning and artificial intelligence, providing tools to build and train models, including pre-trained VGG models.

VGG:
Visual Geometry Group's standard deep CNN architecture. VGG-19 is used for feature extraction in this project.

OS:
Provides functions for interacting with the operating system.

CV2:
OpenCV for Python, used for image processing tasks such as reading and manipulating images.

PIL:
Python Imaging Library, used for opening, manipulating, and saving different image file formats.

Usage
Choose your content and style images.
Run all the code cells in the Jupyter notebook to perform the style transfer.
The final stylized image will be saved automatically.
Examples
The following is an example of a style transfer result using this project:

Original Images:
Content Image:

Style Image:

Result:

Author
Archie Agarwal - If you have any questions or suggestions, feel free to contact me at archie_agarwal@domain.com.
